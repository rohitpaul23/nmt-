{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohitpaul23/nmt-/blob/main/NMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY80VRKqnRrD"
      },
      "source": [
        "#Neural Machine Translation\n",
        "\n",
        "An English-to-German neural machine translation (NMT) model using Long Short-Term Memory (LSTM) networks with attention. Machine translation is an important task in natural language processing and could be useful not only for translating one language to another but also for word sense disambiguation (e.g. determining whether the word \"bank\" refers to the financial bank, or the land alongside a river). Implementing this using just a Recurrent Neural Network (RNN) with LSTMs can work for short to medium length sentences but can result in vanishing gradients for very long sequences. To solve this, you will be adding an attention mechanism to allow the decoder to access all relevant parts of the input sentence regardless of its length."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnVLO0uBnrSn"
      },
      "source": [
        "##Outline\n",
        "1. Data Preparation\n",
        "2. Neural Machine Translation with Attention\n",
        "3. Training\n",
        "4. Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB9vacDmoFxS"
      },
      "source": [
        "##Data Preparation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEtfcDRhqtmi"
      },
      "source": [
        "###Importing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILZ3Ilyfrk9F",
        "outputId": "53d84a56-21e5-4105-d435-dab9f8b8d8fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting trax\n",
            "  Downloading trax-1.4.1-py2.py3-none-any.whl (637 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m637.9/637.9 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from trax) (4.6.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.8/dist-packages (from trax) (0.25.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.8/dist-packages (from trax) (0.3.25+cuda11.cudnn805)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from trax) (5.4.8)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.8/dist-packages (from trax) (0.3.25)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from trax) (1.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from trax) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from trax) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from trax) (1.7.3)\n",
            "Collecting funcsigs\n",
            "  Downloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from trax) (0.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from trax) (1.15.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym->trax) (1.5.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym->trax) (5.2.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym->trax) (0.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from jax->trax) (4.4.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax->trax) (3.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->trax) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->trax) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->trax) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->trax) (3.0.9)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->trax) (3.19.6)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->trax) (0.10.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->trax) (5.10.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->trax) (2.25.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->trax) (2.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->trax) (2.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->trax) (4.64.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->trax) (1.12.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->trax) (0.9.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->trax) (0.3.6)\n",
            "Collecting tensorflow<2.12,>=2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-text->trax) (0.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym->trax) (3.11.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (4.0.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (1.14.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (21.3)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.29.0)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (1.51.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (1.6.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (14.0.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow-datasets->trax) (1.57.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.38.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (2.15.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (1.8.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text->trax) (3.2.2)\n",
            "Installing collected packages: funcsigs, flatbuffers, tensorflow-estimator, keras, tensorboard, tensorflow, tensorflow-text, trax\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-22.12.6 funcsigs-1.0.2 keras-2.11.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-text-2.11.0 trax-1.4.1\n"
          ]
        }
      ],
      "source": [
        "pip install trax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws17k1s2m2kn",
        "outputId": "69446556-04d4-4b6f-c24f-eddfb3d66c0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trax                          1.4.1\n"
          ]
        }
      ],
      "source": [
        "from termcolor import colored\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import trax\n",
        "from trax import layers as tl\n",
        "from trax.fastmath import numpy as fastnp\n",
        "from trax.supervised import training\n",
        "\n",
        "!pip list | grep trax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ISDxBmMrJwj"
      },
      "source": [
        "Will just use a small dataset from Opus, a growing collection of translated texts from the web. Particularly, we will get an English to German translation subset specified as opus/medical which has medical related texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_xRZiRFprL4g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "27e0fdd437d3430f845f7c9fccef0074",
            "b2b3552819b249bca58fc49869dd8f99",
            "bf0fa92b83844d6ba325fa88da57801c",
            "e95f2799e1b140d4808d1b08dcbb2594",
            "d7c1c25ed30f401487291c626cc47f89",
            "a7d52cd5e8764fb7a4319a2b20b32a5d",
            "cb5c3ee898f544d884ac7e09176cb9bf",
            "110f11be7d354be58715f110ea22fa81",
            "bc76b52a759449eb9e1ec574463c174e",
            "c5f0edf88d72480085279e88baf77e92",
            "53a025f085cf487c8e65bbf1d677e030",
            "5e3421fecdff4821b7aab758193d7dd4",
            "6e16cb88c7264c6289c1f642760c9670",
            "de0866419ff24a9b9fc417910bb8fa1d",
            "6cc8fbdd73c74c1e95e33c26e0a90553",
            "249002301b654123b2d8b19c3abdf2e2",
            "e990eaf57171448c9f4264dc3c820a85",
            "c1dbd727a2334976a8818908fae4cc4f",
            "1dfd26dd16eb45a58682cb8d4323751e",
            "142bafb2e84c46e2a3597bf03bbce27a",
            "0ab20c49d4fa44bcbd5c7bd850c6ef2a",
            "9d5f193b195a4e82bf0ad89991860226",
            "8a3a41b94c324e00aecf501f55bbd6e6",
            "331b05c1b5a446ecbe6f1d17c5e45dde",
            "98e52c75cc1841ad9ae5986aa849d72a",
            "0f27c9199347466182f7c1810710c0ec",
            "0177e7532f42434d82858d58ecf40897",
            "7bf0906afc8b4e18ae0677db901978a8",
            "d2a64d28f9ad4413b817ea0184fd6950",
            "331d7044e54f44e9ba3ae931357434a0",
            "54192e55b9ec4e8d958ba26ca4207102",
            "7084d2a26c1a4272ae1d88a6db3e9d06",
            "c94577c7bf284d97b8f5fe63c3674d86",
            "620489a85cda4fbcab0126ea4c77b163",
            "8dae73bc2fc7409b902eb1be45668457",
            "c15583fc61be454899432042e91469cb",
            "b9b2dc432dee4e79a8cd6c814d29f0ee",
            "5afb61c79031401bade793fedb737149",
            "e2b38bc1fd88470aa34b71a51bcf17f3",
            "7df762cb64294493872ebf562593dc55",
            "84d3b4c72f17441eac4b6a56d0712f91",
            "dbc48e9dfbc649638ba01c25d0340e53",
            "03469cda67274859a6a14ea39c072f66",
            "a41b98ce1faf4db1809ce7c6a8f43661",
            "abcc08e028d34bb3af2d0d4a98a7336b",
            "4a912cc9392d4f99aaa626572408645f",
            "285d6e29754d4b92911a217ee4a0c33c",
            "069786d2e88c4fcb87a2e20ff9c7c8ae",
            "ec6be27d9b81450ba17a04bb924d7c86",
            "69f08f1b00254e2ab51a9724392c1173",
            "1bc80c204ecd482ab3be7ffb203d8395",
            "46e9c35740734e7f9100d0115b1bcdd8",
            "3699ebce8f954362af0e0c8d258f58b9",
            "0a5051a6015b48679f6a087d66071418",
            "d95cef6dd8af44beabb2db91a2ba3cfb",
            "4caff371d93e46c5916034e9f46e0ef4",
            "d5d2e20376b942fa96ce32578246dfa9",
            "5c0bb740af7f49798d52d423323dabed",
            "90b245cee7894b189652708f132c5aaf",
            "4fc4ceeb86764293b265295081d76126",
            "63da461635044eb790b51cc26ce98f1c",
            "ec4d7f8b3c8f493aa5f5cb0d31db985f",
            "14c441b7d4b247da9eb0c60d5667cbd2",
            "16088c9346f84bdc9829d9d715b149f4",
            "5c1df4203f664f358fae98f5b0f51b56",
            "9b65199b366248df8b5b1eea539cc809"
          ]
        },
        "outputId": "90d62ce6-588c-4d6f-f4a9-8ed3aef063ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
            "/usr/local/lib/python3.8/dist-packages/jax/_src/lib/xla_bridge.py:553: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 34.29 MiB (download: 34.29 MiB, generated: 188.85 MiB, total: 223.13 MiB) to ./data/opus/medical/0.1.0...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27e0fdd437d3430f845f7c9fccef0074"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e3421fecdff4821b7aab758193d7dd4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extraction completed...: 0 file [00:00, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a3a41b94c324e00aecf501f55bbd6e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "620489a85cda4fbcab0126ea4c77b163"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train examples...:   0%|          | 0/1108752 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abcc08e028d34bb3af2d0d4a98a7336b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Shuffling data/opus/medical/0.1.0.incomplete0QLOER/opus-train.tfrecord*...:   0%|          | 0/1108752 [00:00<…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4caff371d93e46c5916034e9f46e0ef4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset opus downloaded and prepared to ./data/opus/medical/0.1.0. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "# Get generator function for the training set\n",
        "train_stream_fn = trax.data.TFDS('opus/medical',\n",
        "                                 data_dir='./data/',\n",
        "                                 keys=('en', 'de'),\n",
        "                                 eval_holdout_size=0.01, # 1% for eval\n",
        "                                 train=True)\n",
        "\n",
        "# Get generator function for the eval set\n",
        "eval_stream_fn = trax.data.TFDS('opus/medical',\n",
        "                                data_dir='./data/',\n",
        "                                keys=('en', 'de'),\n",
        "                                eval_holdout_size=0.01, # 1% for eval\n",
        "                                train=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_stream = train_stream_fn()\n",
        "print(colored('train data (en, de) tuple:', 'red'), next(train_stream))\n",
        "print()\n",
        "\n",
        "eval_stream = eval_stream_fn()\n",
        "print(colored('eval data (en, de) tuple:', 'red'), next(eval_stream))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZFH8l4PtOj-",
        "outputId": "9eabcd82-93ce-4d58-fef1-024379f6d562"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data (en, de) tuple: (b'Tel: +421 2 57 103 777\\n', b'Tel: +421 2 57 103 777\\n')\n",
            "\n",
            "eval data (en, de) tuple: (b'Subcutaneous use and intravenous use.\\n', b'Subkutane Anwendung und intraven\\xc3\\xb6se Anwendung.\\n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tokenization and Formatting"
      ],
      "metadata": {
        "id": "WIfhmanStmtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rohitpaul23/nmt-.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL3qeqjytePS",
        "outputId": "5a821649-2d37-4de3-9ae3-d857f37d6076"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nmt-'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 12 (delta 2), reused 5 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (12/12), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COxc3N3kNYQP",
        "outputId": "9583408c-f996-4233-95ce-a0f48e224419"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  nmt-  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_FILE = 'ende_32k.subword'\n",
        "VOCAB_DIR = 'nmt-/data'\n",
        "\n",
        "# Tokenize the dataset.\n",
        "tokenized_train_stream = trax.data.Tokenize(vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR)(train_stream)\n",
        "tokenized_eval_stream = trax.data.Tokenize(vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR)(eval_stream)"
      ],
      "metadata": {
        "id": "FaOOlit6Nlrh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(trax.data.tokenize(iter(['HELLO']), vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLXSjvGJhki8",
        "outputId": "cfa5e0a5-d5fe-4cde-c761-bb722b8c22c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7046, 7502,  809])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Append EOS at the end of each sentence.\n",
        "\n",
        "# Integer assigned as end-of-sentence (EOS)\n",
        "EOS = 1\n",
        "\n",
        "# generator helper function to append EOS to each sentence\n",
        "def append_eos(stream):\n",
        "    for (inputs, targets) in stream:\n",
        "        inputs_with_eos = list(inputs) + [EOS]\n",
        "        targets_with_eos = list(targets) + [EOS]\n",
        "        yield np.array(inputs_with_eos), np.array(targets_with_eos)\n",
        "\n",
        "# append EOS to the train data\n",
        "tokenized_train_stream = append_eos(tokenized_train_stream)\n",
        "\n",
        "# append EOS to the eval data\n",
        "tokenized_eval_stream = append_eos(tokenized_eval_stream)"
      ],
      "metadata": {
        "id": "SlsWJzYqOG8f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Filter too long sentences to not run out of memory.\n",
        "# length_keys=[0, 1] means we filter both English and German sentences, so\n",
        "# both much be not longer that 256 tokens for training / 512 for eval.\n",
        "filtered_train_stream = trax.data.FilterByLength(\n",
        "    max_length=256, length_keys=[0, 1])(tokenized_train_stream)\n",
        "filtered_eval_stream = trax.data.FilterByLength(\n",
        "    max_length=512, length_keys=[0, 1])(tokenized_eval_stream)\n",
        "\n",
        "# print a sample input-target pair of tokenized sentences\n",
        "train_input, train_target = next(filtered_train_stream)\n",
        "print(colored(f'Single tokenized example input:', 'red' ), train_input)\n",
        "print(colored(f'Single tokenized example target:', 'red'), train_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_CnP_PTPPCS",
        "outputId": "8ad420da-0cbd-44e6-8e83-8b815d823b51"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single tokenized example input: [ 2538  2248    30 12114 23184 16889     5     2 20852  6456 20592  5812\n",
            "  3932    96  5178  3851    30  7891  3550 30650  4729   992     1]\n",
            "Single tokenized example target: [ 1872    11  3544    39  7019 17877 30432    23  6845    10 14222    47\n",
            "  4004    18 21674     5 27467  9513   920   188 10630    18  3550 30650\n",
            "  4729   992     1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tokenize & detokenize helper functions"
      ],
      "metadata": {
        "id": "z49ZCjziOqQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def tokenize(input_str, vocab_file=None, vocab_dir=None):\n",
        "    \"\"\"Encodes a string to an array of integers\n",
        "\n",
        "    Args:\n",
        "        input_str (str): human-readable string to encode\n",
        "        vocab_file (str): filename of the vocabulary text file\n",
        "        vocab_dir (str): path to the vocabulary file\n",
        "  \n",
        "    Returns:\n",
        "        numpy.ndarray: tokenized version of the input string\n",
        "    \"\"\"\n",
        "    \n",
        "    # Set the encoding of the \"end of sentence\" as 1\n",
        "    EOS = 1\n",
        "    \n",
        "    # Use the trax.data.tokenize method. It takes streams and returns streams,\n",
        "    # we get around it by making a 1-element stream with `iter`.\n",
        "    inputs =  next(trax.data.tokenize(iter([input_str]),\n",
        "                                      vocab_file=vocab_file, vocab_dir=vocab_dir))\n",
        "    \n",
        "    # Mark the end of the sentence with EOS\n",
        "    inputs = list(inputs) + [EOS]\n",
        "    \n",
        "    # Adding the batch dimension to the front of the shape\n",
        "    batch_inputs = np.reshape(np.array(inputs), [1, -1])\n",
        "    \n",
        "    return batch_inputs\n",
        "\n",
        "\n",
        "def detokenize(integers, vocab_file=None, vocab_dir=None):\n",
        "    \"\"\"Decodes an array of integers to a human readable string\n",
        "\n",
        "    Args:\n",
        "        integers (numpy.ndarray): array of integers to decode\n",
        "        vocab_file (str): filename of the vocabulary text file\n",
        "        vocab_dir (str): path to the vocabulary file\n",
        "  \n",
        "    Returns:\n",
        "        str: the decoded sentence.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Remove the dimensions of size 1\n",
        "    integers = list(np.squeeze(integers))\n",
        "    \n",
        "    # Set the encoding of the \"end of sentence\" as 1\n",
        "    EOS = 1\n",
        "    \n",
        "    # Remove the EOS to decode only the original tokens\n",
        "    if EOS in integers:\n",
        "        integers = integers[:integers.index(EOS)] \n",
        "    \n",
        "    return trax.data.detokenize(integers, vocab_file=vocab_file, vocab_dir=vocab_dir)\n",
        "    "
      ],
      "metadata": {
        "id": "fSRyyLYfOto7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Single tokenized example input:', train_input)\n",
        "print('Single tokenized example target:', train_target)\n",
        "print()\n",
        "\n",
        "# Detokenize an input-target pair of tokenized sentences\n",
        "print(colored(f'Single detokenized example input:', 'red'), detokenize(train_input, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR))\n",
        "print(colored(f'Single detokenized example target:', 'red'), detokenize(train_target, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR))\n",
        "print()\n",
        "\n",
        "# Tokenize and detokenize a word that is not explicitly saved in the vocabulary file.\n",
        "# See how it combines the subwords -- 'hell' and 'o'-- to form the word 'hello'.\n",
        "print(colored(f\"tokenize('hello'): \", 'green'), tokenize('hello', vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR))\n",
        "print(colored(f\"detokenize([17332, 140, 1]): \", 'green'), detokenize([17332, 140, 1], vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAjjGaoRQdzh",
        "outputId": "cd0762e8-db16-4c46-fd5b-37c3cb87a1f5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single tokenized example input: [ 2538  2248    30 12114 23184 16889     5     2 20852  6456 20592  5812\n",
            "  3932    96  5178  3851    30  7891  3550 30650  4729   992     1]\n",
            "Single tokenized example target: [ 1872    11  3544    39  7019 17877 30432    23  6845    10 14222    47\n",
            "  4004    18 21674     5 27467  9513   920   188 10630    18  3550 30650\n",
            "  4729   992     1]\n",
            "\n",
            "Single detokenized example input: During treatment with olanzapine, adolescents gained significantly more weight compared with adults.\n",
            "\n",
            "Single detokenized example target: Während der Behandlung mit Olanzapin nahmen die Jugendlichen im Vergleich zu Erwachsenen signifikant mehr Gewicht zu.\n",
            "\n",
            "\n",
            "tokenize('hello'):  [[17332   140     1]]\n",
            "detokenize([17332, 140, 1]):  hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Bucketing"
      ],
      "metadata": {
        "id": "84L6q5NxROnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bucketing to create streams of batches.\n",
        "\n",
        "# Buckets are defined in terms of boundaries and batch sizes.\n",
        "# Batch_sizes[i] determines the batch size for items with length < boundaries[i]\n",
        "# So below, we'll take a batch of 256 sentences of length < 8, 128 if length is\n",
        "# between 8 and 16, and so on -- and only 2 if length is over 512.\n",
        "boundaries =  [8,   16,  32, 64, 128, 256, 512]\n",
        "batch_sizes = [256, 128, 64, 32, 16,    8,   4,  2]\n",
        "\n",
        "# Create the generators.\n",
        "train_batch_stream = trax.data.BucketByLength(\n",
        "    boundaries, batch_sizes,\n",
        "    length_keys=[0, 1]  # As before: count inputs and targets to length.\n",
        ")(filtered_train_stream)\n",
        "\n",
        "eval_batch_stream = trax.data.BucketByLength(\n",
        "    boundaries, batch_sizes,\n",
        "    length_keys=[0, 1]  # As before: count inputs and targets to length.\n",
        ")(filtered_eval_stream)\n",
        "\n",
        "# Add masking for the padding (0s).\n",
        "train_batch_stream = trax.data.AddLossWeights(id_to_mask=0)(train_batch_stream)\n",
        "eval_batch_stream = trax.data.AddLossWeights(id_to_mask=0)(eval_batch_stream)"
      ],
      "metadata": {
        "id": "6p0DM6dRQ_QO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exploring the data"
      ],
      "metadata": {
        "id": "9RAu4y8rR8XT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_batch, target_batch, mask_batch = next(train_batch_stream)\n",
        "\n",
        "# let's see the data type of a batch\n",
        "print(\"input_batch data type: \", type(input_batch))\n",
        "print(\"target_batch data type: \", type(target_batch))\n",
        "\n",
        "# let's see the shape of this particular batch (batch length, sentence length)\n",
        "print(\"input_batch shape: \", input_batch.shape)\n",
        "print(\"target_batch shape: \", target_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um4ktzu9R9-0",
        "outputId": "46ea6d73-9c56-43ae-b011-b539744c59b8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_batch data type:  <class 'numpy.ndarray'>\n",
            "target_batch data type:  <class 'numpy.ndarray'>\n",
            "input_batch shape:  (32, 64)\n",
            "target_batch shape:  (32, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pick a random index less than the batch size.\n",
        "index = random.randrange(len(input_batch))\n",
        "\n",
        "# use the index to grab an entry from the input and target batch\n",
        "print(colored('THIS IS THE ENGLISH SENTENCE: \\n', 'red'), detokenize(input_batch[index], vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR), '\\n')\n",
        "print(colored('THIS IS THE TOKENIZED VERSION OF THE ENGLISH SENTENCE: \\n ', 'red'), input_batch[index], '\\n')\n",
        "print(colored('THIS IS THE GERMAN TRANSLATION: \\n', 'red'), detokenize(target_batch[index], vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR), '\\n')\n",
        "print(colored('THIS IS THE TOKENIZED VERSION OF THE GERMAN TRANSLATION: \\n', 'red'), target_batch[index], '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFxWbEIeSftT",
        "outputId": "1c7ecad2-b84f-432a-e621-980ccbe8da5a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THIS IS THE ENGLISH SENTENCE: \n",
            " 11/ 19 MINIMUM PARTICULARS TO APPEAR ON SMALL IMMEDIATE PACKAGING UNITS\n",
            " \n",
            "\n",
            "THIS IS THE TOKENIZED VERSION OF THE ENGLISH SENTENCE: \n",
            "  [  665  6722  1245 31674  8526 11459     5 21279  6998 12945  6655 15854\n",
            " 10486  8067 10540  4206     5  6638  7948 32939  8526 15959  8528 11471\n",
            "  9785 21797 18792 12827  5106  5386   331 30650  4729   992     1     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0] \n",
            "\n",
            "THIS IS THE GERMAN TRANSLATION: \n",
            " 12/20 MINDESTANGABEN AUF KLEINEN PRIMÄRVERPACKUNGEN\n",
            " \n",
            "\n",
            "THIS IS THE TOKENIZED VERSION OF THE GERMAN TRANSLATION: \n",
            " [  649   123   384 31674  5152  9767  9797  6710  2872  9227  1100 31844\n",
            " 10676  4017  1046 11538  1489  3449  3145 10468  9785 21797  5106 16071\n",
            "     5 30650  4729   992     1     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Neural Machine Translation with Attention"
      ],
      "metadata": {
        "id": "a00hphgqShVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input Encoder."
      ],
      "metadata": {
        "id": "f1jzGGx5VsX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def input_encoder_fn(input_vocab_size, d_model, n_encoder_layers):\n",
        "    \"\"\" Input encoder runs on the input sentence and creates\n",
        "    activations that will be the keys and values for attention.\n",
        "    \n",
        "    Args:\n",
        "        input_vocab_size: int: vocab size of the input\n",
        "        d_model: int:  depth of embedding (n_units in the LSTM cell)\n",
        "        n_encoder_layers: int: number of LSTM layers in the encoder\n",
        "    Returns:\n",
        "        tl.Serial: The input encoder\n",
        "    \"\"\"\n",
        "    \n",
        "    # create a serial network\n",
        "    input_encoder = tl.Serial( \n",
        "        \n",
        "        # create an embedding layer to convert tokens to vectors\n",
        "        tl.Embedding(vocab_size=input_vocab_size, d_feature=d_model),\n",
        "        \n",
        "        # feed the embeddings to the LSTM layers. It is a stack of n_encoder_layers LSTM layers\n",
        "        [tl.LSTM(n_units=d_model) for _ in range(n_encoder_layers)]\n",
        "    )\n",
        "\n",
        "    return input_encoder"
      ],
      "metadata": {
        "id": "yjw_U6sySnIp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-attention Decoder"
      ],
      "metadata": {
        "id": "5KU-deHzVwi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def pre_attention_decoder_fn(mode, target_vocab_size, d_model):\n",
        "    \"\"\" Pre-attention decoder runs on the targets and creates\n",
        "    activations that are used as queries in attention.\n",
        "    \n",
        "    Args:\n",
        "        mode: str: 'train' or 'eval'\n",
        "        target_vocab_size: int: vocab size of the target\n",
        "        d_model: int:  depth of embedding (n_units in the LSTM cell)\n",
        "    Returns:\n",
        "        tl.Serial: The pre-attention decoder\n",
        "    \"\"\"\n",
        "    \n",
        "    # create a serial network\n",
        "    pre_attention_decoder = tl.Serial(\n",
        "        \n",
        "        # shift right to insert start-of-sentence token and implement\n",
        "        # teacher forcing during training\n",
        "        tl.ShiftRight(mode=mode),\n",
        "\n",
        "        # run an embedding layer to convert tokens to vectors\n",
        "        tl.Embedding(vocab_size=target_vocab_size, d_feature=d_model),\n",
        "\n",
        "        # feed to an LSTM layer\n",
        "        tl.LSTM(n_units=d_model)\n",
        "    )\n",
        "    \n",
        "    return pre_attention_decoder"
      ],
      "metadata": {
        "id": "Es8AhZa8V06O"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing the attention input"
      ],
      "metadata": {
        "id": "3gttdGOqWZ5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_attention_input(encoder_activations, decoder_activations, inputs):\n",
        "    \"\"\"Prepare queries, keys, values and mask for attention.\n",
        "    \n",
        "    Args:\n",
        "        encoder_activations fastnp.array(batch_size, padded_input_length, d_model): output from the input encoder\n",
        "        decoder_activations fastnp.array(batch_size, padded_input_length, d_model): output from the pre-attention decoder\n",
        "        inputs fastnp.array(batch_size, padded_input_length): padded input tokens\n",
        "    \n",
        "    Returns:\n",
        "        queries, keys, values and mask for attention.\n",
        "    \"\"\"\n",
        "    \n",
        "    # set the keys and values to the encoder activations\n",
        "    keys = encoder_activations\n",
        "    values = encoder_activations\n",
        "\n",
        "    \n",
        "    # set the queries to the decoder activations\n",
        "    queries = decoder_activations\n",
        "    \n",
        "    # generate the mask to distinguish real tokens from padding\n",
        "    # hint: inputs is 1 for real tokens and 0 where they are padding\n",
        "    mask = inputs != 0\n",
        "    \n",
        "    \n",
        "    # add axes to the mask for attention heads and decoder length.\n",
        "    mask = fastnp.reshape(mask, (mask.shape[0], 1, 1, mask.shape[1]))\n",
        "    \n",
        "    # broadcast so mask shape is [batch size, attention heads, decoder-len, encoder-len].\n",
        "    # note: attention heads is set to 1.\n",
        "    mask = mask + fastnp.zeros((1, 1, decoder_activations.shape[1], 1))\n",
        "        \n",
        "    \n",
        "    return queries, keys, values, mask"
      ],
      "metadata": {
        "id": "Tx7TmzZTWX0n"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation"
      ],
      "metadata": {
        "id": "syrhdkHcYu9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NMTAttn(input_vocab_size=33300,\n",
        "            target_vocab_size=33300,\n",
        "            d_model=1024,\n",
        "            n_encoder_layers=2,\n",
        "            n_decoder_layers=2,\n",
        "            n_attention_heads=4,\n",
        "            attention_dropout=0.0,\n",
        "            mode='train'):\n",
        "    \"\"\"Returns an LSTM sequence-to-sequence model with attention.\n",
        "\n",
        "    The input to the model is a pair (input tokens, target tokens), e.g.,\n",
        "    an English sentence (tokenized) and its translation into German (tokenized).\n",
        "\n",
        "    Args:\n",
        "    input_vocab_size: int: vocab size of the input\n",
        "    target_vocab_size: int: vocab size of the target\n",
        "    d_model: int:  depth of embedding (n_units in the LSTM cell)\n",
        "    n_encoder_layers: int: number of LSTM layers in the encoder\n",
        "    n_decoder_layers: int: number of LSTM layers in the decoder after attention\n",
        "    n_attention_heads: int: number of attention heads\n",
        "    attention_dropout: float, dropout for the attention layer\n",
        "    mode: str: 'train', 'eval' or 'predict', predict mode is for fast inference\n",
        "\n",
        "    Returns:\n",
        "    A LSTM sequence-to-sequence model with attention.\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 0: call the helper function to create layers for the input encoder\n",
        "    input_encoder = input_encoder_fn(input_vocab_size, d_model, n_encoder_layers)\n",
        "\n",
        "    # Step 0: call the helper function to create layers for the pre-attention decoder\n",
        "    pre_attention_decoder = pre_attention_decoder_fn(mode, target_vocab_size, d_model)\n",
        "\n",
        "    # Step 1: create a serial network\n",
        "    model = tl.Serial( \n",
        "        \n",
        "      # Step 2: copy input tokens and target tokens as they will be needed later.\n",
        "      tl.Select([0,1,0,1]),\n",
        "        \n",
        "      # Step 3: run input encoder on the input and pre-attention decoder the target.\n",
        "      tl.Parallel(input_encoder, pre_attention_decoder),\n",
        "        \n",
        "      # Step 4: prepare queries, keys, values and mask for attention.\n",
        "      tl.Fn('PrepareAttentionInput', prepare_attention_input, n_out=4),\n",
        "        \n",
        "      # Step 5: run the AttentionQKV layer\n",
        "      # nest it inside a Residual layer to add to the pre-attention decoder activations(i.e. queries)\n",
        "      tl.Residual(tl.AttentionQKV(d_model, n_heads=n_attention_heads, dropout=attention_dropout, mode=mode)),\n",
        "      \n",
        "      # Step 6: drop attention mask (i.e. index = None\n",
        "      tl.Select([0,2]),\n",
        "        \n",
        "      # Step 7: run the rest of the RNN decoder\n",
        "      [tl.LSTM(n_units=d_model) for _ in range(n_decoder_layers)],\n",
        "        \n",
        "      # Step 8: prepare output by making it the right size\n",
        "      tl.Dense(target_vocab_size),\n",
        "        \n",
        "      # Step 9: Log-softmax for output\n",
        "       tl.LogSoftmax()\n",
        "    )\n",
        "    \n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "ZCzGSR-6Yukn"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NMTAttn()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MajU5C8ZZOfA",
        "outputId": "81b0fa4a-036f-4d1f-c127-ba130102b4bd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Serial_in2_out2[\n",
            "  Select[0,1,0,1]_in2_out4\n",
            "  Parallel_in2_out2[\n",
            "    Serial[\n",
            "      Embedding_33300_1024\n",
            "      LSTM_1024\n",
            "      LSTM_1024\n",
            "    ]\n",
            "    Serial[\n",
            "      Serial[\n",
            "        ShiftRight(1)\n",
            "      ]\n",
            "      Embedding_33300_1024\n",
            "      LSTM_1024\n",
            "    ]\n",
            "  ]\n",
            "  PrepareAttentionInput_in3_out4\n",
            "  Serial_in4_out2[\n",
            "    Branch_in4_out3[\n",
            "      None\n",
            "      Serial_in4_out2[\n",
            "        _in4_out4\n",
            "        Serial_in4_out2[\n",
            "          Parallel_in3_out3[\n",
            "            Dense_1024\n",
            "            Dense_1024\n",
            "            Dense_1024\n",
            "          ]\n",
            "          PureAttention_in4_out2\n",
            "          Dense_1024\n",
            "        ]\n",
            "        _in2_out2\n",
            "      ]\n",
            "    ]\n",
            "    Add_in2\n",
            "  ]\n",
            "  Select[0,2]_in3_out2\n",
            "  LSTM_1024\n",
            "  LSTM_1024\n",
            "  Dense_33300\n",
            "  LogSoftmax\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training"
      ],
      "metadata": {
        "id": "M5VBx1umZSpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_task = training.TrainTask(\n",
        "        \n",
        "    # use the train batch stream as labeled data\n",
        "    labeled_data= train_batch_stream,\n",
        "    \n",
        "    # use the cross entropy loss\n",
        "    loss_layer= tl.CrossEntropyLoss(),\n",
        "    \n",
        "    # use the Adam optimizer with learning rate of 0.01\n",
        "    optimizer= trax.optimizers.Adam(0.01),\n",
        "    \n",
        "    # use the `trax.lr.warmup_and_rsqrt_decay` as the learning rate schedule\n",
        "    # have 1000 warmup steps with a max value of 0.01\n",
        "    lr_schedule= trax.lr.warmup_and_rsqrt_decay(1000, 0.01),\n",
        "    \n",
        "    # have a checkpoint every 10 steps\n",
        "    n_steps_per_checkpoint= 10,\n",
        "    \n",
        ")"
      ],
      "metadata": {
        "id": "TDqv04mSZWVl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_task = training.EvalTask(\n",
        "    \n",
        "    ## use the eval batch stream as labeled data\n",
        "    labeled_data=eval_batch_stream,\n",
        "    \n",
        "    ## use the cross entropy loss and accuracy as metrics\n",
        "    metrics=[tl.CrossEntropyLoss(), tl.Accuracy()],\n",
        ")"
      ],
      "metadata": {
        "id": "Gml1PWoJZmk_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the output directory\n",
        "output_dir = 'output_dir/'\n",
        "\n",
        "# remove old model if it exists. restarts training.\n",
        "!rm -f ~/output_dir/model.pkl.gz  \n",
        "\n",
        "# define the training loop\n",
        "training_loop = training.Loop(NMTAttn(mode='train'),\n",
        "                              train_task,\n",
        "                              eval_tasks=[eval_task],\n",
        "                              output_dir=output_dir)"
      ],
      "metadata": {
        "id": "9lTvYOXYZoRh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: Execute the training loop.\n",
        "training_loop.run(25)"
      ],
      "metadata": {
        "id": "93N7mrAzZ2DL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61d19dbb-5b84-4ee7-c1ac-1603768e5ce7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step      1: Total number of trainable weights: 148492820\n",
            "Step      1: Ran 1 train steps in 130.26 secs\n",
            "Step      1: train CrossEntropyLoss |  10.41469097\n",
            "Step      1: eval  CrossEntropyLoss |  10.41237354\n",
            "Step      1: eval          Accuracy |  0.00000000\n",
            "\n",
            "Step     10: Ran 9 train steps in 426.25 secs\n",
            "Step     10: train CrossEntropyLoss |  10.24593544\n",
            "Step     10: eval  CrossEntropyLoss |  9.94970703\n",
            "Step     10: eval          Accuracy |  0.03264996\n",
            "\n",
            "Step     20: Ran 10 train steps in 466.16 secs\n",
            "Step     20: train CrossEntropyLoss |  9.44432926\n",
            "Step     20: eval  CrossEntropyLoss |  8.92920971\n",
            "Step     20: eval          Accuracy |  0.01341752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing"
      ],
      "metadata": {
        "id": "uIy-VF0taCmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate the model we built in eval mode\n",
        "model = NMTAttn(mode='eval')\n",
        "\n",
        "# initialize weights from a pre-trained model\n",
        "model.init_from_file(\"output_dir/model.pkl.gz\", weights_only=True)\n",
        "model = tl.Accelerate(model)"
      ],
      "metadata": {
        "id": "omZnFYgIaFqe"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoding"
      ],
      "metadata": {
        "id": "kSINk44MaXxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def next_symbol(NMTAttn, input_tokens, cur_output_tokens, temperature):\n",
        "    \"\"\"Returns the index of the next token.\n",
        "\n",
        "    Args:\n",
        "        NMTAttn (tl.Serial): An LSTM sequence-to-sequence model with attention.\n",
        "        input_tokens (np.ndarray 1 x n_tokens): tokenized representation of the input sentence\n",
        "        cur_output_tokens (list) tokenized representation of previously translated words\n",
        "        temperature (float): parameter for sampling ranging from 0.0 to 1.0.\n",
        "            0.0: same as argmax, always pick the most probable token\n",
        "            1.0: sampling from the distribution (can sometimes say random things)\n",
        "\n",
        "    Returns:\n",
        "        int: index of the next token in the translated sentence\n",
        "        float: log probability of the next symbol\n",
        "    \"\"\"\n",
        "\n",
        "    # set the length of the current output tokens\n",
        "    token_length = len(cur_output_tokens)\n",
        "\n",
        "    # calculate next power of 2 for padding length \n",
        "    padded_length = np.power(2, int(np.ceil(np.log2(token_length + 1))))\n",
        "\n",
        "    # pad cur_output_tokens up to the padded_length\n",
        "    padded = cur_output_tokens + [0] * (padded_length - token_length)\n",
        "    \n",
        "    \n",
        "    # model expects the output to have an axis for the batch size in front so\n",
        "    # convert `padded` list to a numpy array with shape (None, <padded_length>) where\n",
        "    # None is a placeholder for the batch size\n",
        "    padded_with_batch = np.expand_dims(padded, axis=0)\n",
        "\n",
        "    # get the model prediction (remember to use the `NMAttn` argument defined above)\n",
        "    output, _ = NMTAttn((input_tokens, padded_with_batch))\n",
        "    \n",
        "    # get log probabilities from the last token output\n",
        "    log_probs = output[0, token_length, :]\n",
        "\n",
        "    # get the next symbol by getting a logsoftmax sample (*hint: cast to an int)\n",
        "    symbol = int(tl.logsoftmax_sample(log_probs, temperature))\n",
        "    \n",
        "    return symbol, float(log_probs[symbol])"
      ],
      "metadata": {
        "id": "Koa3l4AuaVT-"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sampling_decode(input_sentence, NMTAttn = None, temperature=0.0, vocab_file=None, vocab_dir=None):\n",
        "    \"\"\"Returns the translated sentence.\n",
        "\n",
        "    Args:\n",
        "        input_sentence (str): sentence to translate.\n",
        "        NMTAttn (tl.Serial): An LSTM sequence-to-sequence model with attention.\n",
        "        temperature (float): parameter for sampling ranging from 0.0 to 1.0.\n",
        "            0.0: same as argmax, always pick the most probable token\n",
        "            1.0: sampling from the distribution (can sometimes say random things)\n",
        "        vocab_file (str): filename of the vocabulary\n",
        "        vocab_dir (str): path to the vocabulary file\n",
        "\n",
        "    Returns:\n",
        "        tuple: (list, str, float)\n",
        "            list of int: tokenized version of the translated sentence\n",
        "            float: log probability of the translated sentence\n",
        "            str: the translated sentence\n",
        "    \"\"\"\n",
        "    \n",
        "    # encode the input sentence\n",
        "    input_tokens = tokenize(input_sentence,vocab_file,vocab_dir)\n",
        "    \n",
        "    # initialize the list of output tokens\n",
        "    cur_output_tokens = []\n",
        "    \n",
        "    # initialize an integer that represents the current output index\n",
        "    cur_output = 0\n",
        "    \n",
        "    # Set the encoding of the \"end of sentence\" as 1\n",
        "    EOS = 1\n",
        "    \n",
        "    # check that the current output is not the end of sentence token\n",
        "    while cur_output != EOS:\n",
        "        \n",
        "        # update the current output token by getting the index of the next word (hint: use next_symbol)\n",
        "        cur_output, log_prob = next_symbol(NMTAttn, input_tokens, cur_output_tokens, temperature)\n",
        "        \n",
        "        # append the current output token to the list of output tokens\n",
        "        cur_output_tokens.append(cur_output)\n",
        "    \n",
        "    # detokenize the output tokens\n",
        "    sentence = detokenize(cur_output_tokens, vocab_file, vocab_dir)\n",
        "    \n",
        "    return cur_output_tokens, log_prob, sentence"
      ],
      "metadata": {
        "id": "KOsLQZQIakav"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detokenize([567, 50, 30650], vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EeX9bo1SO4AG",
        "outputId": "ba7b5d51-a29d-4fa9-f81b-253a00ad83cf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'etwas (\\\\'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trax.data.detokenize([50, 30650], vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GAoVlEM7P6m5",
        "outputId": "dbbb3a23-a1bb-45c1-b04c-f1159850f975"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' (\\\\'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampling_decode(\"Decreased Appetite\", model, temperature=0.25, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dogX6eBmau45",
        "outputId": "8974043a-c3fe-4411-b3ed-9b537c45fd0b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([4859, 1], -7.532810211181641, 'bestehenden')"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_decode_test(sentence, NMTAttn=None, vocab_file=None, vocab_dir=None):\n",
        "    \"\"\"Prints the input and output of our NMTAttn model using greedy decode\n",
        "\n",
        "    Args:\n",
        "        sentence (str): a custom string.\n",
        "        NMTAttn (tl.Serial): An LSTM sequence-to-sequence model with attention.\n",
        "        vocab_file (str): filename of the vocabulary\n",
        "        vocab_dir (str): path to the vocabulary file\n",
        "\n",
        "    Returns:\n",
        "        str: the translated sentence\n",
        "    \"\"\"\n",
        "    \n",
        "    _,_, translated_sentence = sampling_decode(sentence, NMTAttn, temperature=0.3, vocab_file=vocab_file, vocab_dir=vocab_dir)\n",
        "    \n",
        "    print(\"English: \", sentence)\n",
        "    print(\"German: \", translated_sentence)\n",
        "    \n",
        "    return translated_sentence"
      ],
      "metadata": {
        "id": "hbBs3vQQa10k"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# put a custom string here\n",
        "your_sentence = 'I love languages.'\n",
        "\n",
        "greedy_decode_test(your_sentence, model, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR);"
      ],
      "metadata": {
        "id": "ZTtSRYfja8ZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb6c7156-aeac-4aa4-cb93-bf474a8a4a0d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English:  I love languages.\n",
            "German:  Docungen und CH- unge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "greedy_decode_test('You are almost done with the assignment!', model, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR);"
      ],
      "metadata": {
        "id": "uNzr7I35bCrz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e80dc035-736f-4afd-e34c-be556856bd08"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English:  You are almost done with the assignment!\n",
            "German:  gemeinschaftlichen en sollten, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minimum Bayes-Risk Decoding"
      ],
      "metadata": {
        "id": "Q261_KCtbIJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_samples(sentence, n_samples, NMTAttn=None, temperature=0.5, vocab_file=None, vocab_dir=None):\n",
        "    \"\"\"Generates samples using sampling_decode()\n",
        "\n",
        "    Args:\n",
        "        sentence (str): sentence to translate.\n",
        "        n_samples (int): number of samples to generate\n",
        "        NMTAttn (tl.Serial): An LSTM sequence-to-sequence model with attention.\n",
        "        temperature (float): parameter for sampling ranging from 0.0 to 1.0.\n",
        "            0.0: same as argmax, always pick the most probable token\n",
        "            1.0: sampling from the distribution (can sometimes say random things)\n",
        "        vocab_file (str): filename of the vocabulary\n",
        "        vocab_dir (str): path to the vocabulary file\n",
        "        \n",
        "    Returns:\n",
        "        tuple: (list, list)\n",
        "            list of lists: token list per sample\n",
        "            list of floats: log probability per sample\n",
        "    \"\"\"\n",
        "    # define lists to contain samples and probabilities\n",
        "    samples, log_probs = [], []\n",
        "\n",
        "    # run a for loop to generate n samples\n",
        "    for _ in range(n_samples):\n",
        "        \n",
        "        # get a sample using the sampling_decode() function\n",
        "        sample, logp, _ = sampling_decode(sentence, NMTAttn, temperature, vocab_file=vocab_file, vocab_dir=vocab_dir)\n",
        "        \n",
        "        # append the token list to the samples list\n",
        "        samples.append(sample)\n",
        "        \n",
        "        # append the log probability to the log_probs list\n",
        "        log_probs.append(logp)\n",
        "                \n",
        "    return samples, log_probs"
      ],
      "metadata": {
        "id": "KY78cAzubUB8"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate 4 samples with the default temperature (0.5)\n",
        "generate_samples('I love languages.', 4, model, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR)"
      ],
      "metadata": {
        "id": "GzvVPxMMbYlR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e238d5-01d1-4262-9725-7f3a05da31c4"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[29600, 22029, 5527, 129, 3534, 1],\n",
              "  [27853,\n",
              "   4063,\n",
              "   752,\n",
              "   11,\n",
              "   24656,\n",
              "   26621,\n",
              "   11858,\n",
              "   58,\n",
              "   16185,\n",
              "   1888,\n",
              "   3550,\n",
              "   5220,\n",
              "   5193,\n",
              "   11308,\n",
              "   4867,\n",
              "   42,\n",
              "   4729,\n",
              "   24919,\n",
              "   4440,\n",
              "   22361,\n",
              "   15206,\n",
              "   97,\n",
              "   8607,\n",
              "   30797,\n",
              "   928,\n",
              "   29696,\n",
              "   5182,\n",
              "   9385,\n",
              "   20369,\n",
              "   5362,\n",
              "   89,\n",
              "   26708,\n",
              "   4729,\n",
              "   3079,\n",
              "   4064,\n",
              "   9570,\n",
              "   2855,\n",
              "   6751,\n",
              "   21799,\n",
              "   992,\n",
              "   20537,\n",
              "   5785,\n",
              "   30650,\n",
              "   24199,\n",
              "   17488,\n",
              "   1999,\n",
              "   11928,\n",
              "   8553,\n",
              "   17389,\n",
              "   4184,\n",
              "   194,\n",
              "   115,\n",
              "   31897,\n",
              "   9949,\n",
              "   225,\n",
              "   11464,\n",
              "   17068,\n",
              "   30365,\n",
              "   10729,\n",
              "   2796,\n",
              "   992,\n",
              "   39,\n",
              "   23329,\n",
              "   19829,\n",
              "   1786,\n",
              "   10207,\n",
              "   812,\n",
              "   30263,\n",
              "   37,\n",
              "   9220,\n",
              "   3275,\n",
              "   10889,\n",
              "   20229,\n",
              "   2280,\n",
              "   10547,\n",
              "   6393,\n",
              "   27112,\n",
              "   2894,\n",
              "   27,\n",
              "   28198,\n",
              "   5,\n",
              "   8527,\n",
              "   15057,\n",
              "   274,\n",
              "   16210,\n",
              "   3455,\n",
              "   2280,\n",
              "   32079,\n",
              "   4197,\n",
              "   15,\n",
              "   41,\n",
              "   826,\n",
              "   14105,\n",
              "   217,\n",
              "   8471,\n",
              "   11899,\n",
              "   88,\n",
              "   7463,\n",
              "   18139,\n",
              "   4048,\n",
              "   3544,\n",
              "   16179,\n",
              "   27201,\n",
              "   23306,\n",
              "   12920,\n",
              "   10324,\n",
              "   5,\n",
              "   11236,\n",
              "   27503,\n",
              "   13450,\n",
              "   2944,\n",
              "   1],\n",
              "  [18694,\n",
              "   16854,\n",
              "   164,\n",
              "   5,\n",
              "   30175,\n",
              "   18334,\n",
              "   2731,\n",
              "   3932,\n",
              "   8505,\n",
              "   750,\n",
              "   6954,\n",
              "   4022,\n",
              "   78,\n",
              "   22727,\n",
              "   3544,\n",
              "   23573,\n",
              "   367,\n",
              "   13445,\n",
              "   3550,\n",
              "   20864,\n",
              "   11143,\n",
              "   33022,\n",
              "   15722,\n",
              "   17068,\n",
              "   4364,\n",
              "   9250,\n",
              "   9018,\n",
              "   12432,\n",
              "   657,\n",
              "   10071,\n",
              "   1569,\n",
              "   17312,\n",
              "   9214,\n",
              "   10837,\n",
              "   8094,\n",
              "   2257,\n",
              "   23550,\n",
              "   444,\n",
              "   12170,\n",
              "   15761,\n",
              "   5718,\n",
              "   6631,\n",
              "   147,\n",
              "   1082,\n",
              "   24888,\n",
              "   7265,\n",
              "   30650,\n",
              "   30650,\n",
              "   8890,\n",
              "   5,\n",
              "   7994,\n",
              "   3550,\n",
              "   20688,\n",
              "   4574,\n",
              "   7619,\n",
              "   4729,\n",
              "   6426,\n",
              "   23333,\n",
              "   6426,\n",
              "   25174,\n",
              "   17883,\n",
              "   11553,\n",
              "   84,\n",
              "   37,\n",
              "   11515,\n",
              "   19231,\n",
              "   1753,\n",
              "   3423,\n",
              "   30176,\n",
              "   21338,\n",
              "   12189,\n",
              "   838,\n",
              "   1],\n",
              "  [18289, 2370, 9129, 6875, 30544, 30405, 8297, 24054, 493, 24714, 5482, 1]],\n",
              " [-6.8339643478393555,\n",
              "  -6.819344520568848,\n",
              "  -6.819338798522949,\n",
              "  -6.819611072540283])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_similarity(candidate, reference):\n",
        "    \"\"\"Returns the Jaccard similarity between two token lists\n",
        "\n",
        "    Args:\n",
        "        candidate (list of int): tokenized version of the candidate translation\n",
        "        reference (list of int): tokenized version of the reference translation\n",
        "\n",
        "    Returns:\n",
        "        float: overlap between the two token lists\n",
        "    \"\"\"\n",
        "    \n",
        "    # convert the lists to a set to get the unique tokens\n",
        "    can_unigram_set, ref_unigram_set = set(candidate), set(reference)  \n",
        "    \n",
        "    # get the set of tokens common to both candidate and reference\n",
        "    joint_elems = can_unigram_set.intersection(ref_unigram_set)\n",
        "    \n",
        "    # get the set of all tokens found in either candidate or reference\n",
        "    all_elems = can_unigram_set.union(ref_unigram_set)\n",
        "    \n",
        "    # divide the number of joint elements by the number of all elements\n",
        "    overlap = len(joint_elems) / len(all_elems)\n",
        "    \n",
        "    return overlap"
      ],
      "metadata": {
        "id": "8wGOgFppbknJ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jaccard_similarity([1, 2, 3], [1, 2, 3, 4])"
      ],
      "metadata": {
        "id": "-qeldV90bpP9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3b6827-fbc2-46c6-c8f1-ee4e8df4f87a"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def rouge1_similarity(system, reference):\n",
        "    \"\"\"Returns the ROUGE-1 score between two token lists\n",
        "\n",
        "    Args:\n",
        "        system (list of int): tokenized version of the system translation\n",
        "        reference (list of int): tokenized version of the reference translation\n",
        "\n",
        "    Returns:\n",
        "        float: overlap between the two token lists\n",
        "    \"\"\"    \n",
        "    \n",
        "    # make a frequency table of the system tokens (hint: use the Counter class)\n",
        "    sys_counter = Counter(system)\n",
        "    \n",
        "    # make a frequency table of the reference tokens (hint: use the Counter class)\n",
        "    ref_counter = Counter(reference)\n",
        "    \n",
        "    # initialize overlap to 0\n",
        "    overlap = 0\n",
        "    \n",
        "    # run a for loop over the sys_counter object (can be treated as a dictionary)\n",
        "    for token in sys_counter:\n",
        "        \n",
        "        # lookup the value of the token in the sys_counter dictionary (hint: use the get() method)\n",
        "        token_count_sys = sys_counter.get(token,0)\n",
        "        \n",
        "        # lookup the value of the token in the ref_counter dictionary (hint: use the get() method)\n",
        "        token_count_ref = ref_counter.get(token,0)\n",
        "        \n",
        "        # update the overlap by getting the smaller number between the two token counts above\n",
        "        overlap += min(token_count_sys, token_count_ref)\n",
        "    \n",
        "    # get the precision (i.e. number of overlapping tokens / number of system tokens)\n",
        "    precision = overlap / sum(sys_counter.values())\n",
        "    \n",
        "    # get the recall (i.e. number of overlapping tokens / number of reference tokens)\n",
        "    recall = overlap / sum(ref_counter.values())\n",
        "    \n",
        "    if precision + recall != 0:\n",
        "        # compute the f1-score\n",
        "        rouge1_score = 2 * ((precision * recall)/(precision + recall))\n",
        "    else:\n",
        "        rouge1_score = 0 \n",
        "    \n",
        "    return rouge1_score"
      ],
      "metadata": {
        "id": "mAfWwiBAbuPA"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouge1_similarity([1, 2, 3], [1, 2, 3, 4])"
      ],
      "metadata": {
        "id": "1wDX6ckQb3YB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1f94a0b-4e1e-4d70-c9eb-57bd30f19109"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8571428571428571"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def average_overlap(similarity_fn, samples, *ignore_params):\n",
        "    \"\"\"Returns the arithmetic mean of each candidate sentence in the samples\n",
        "\n",
        "    Args:\n",
        "        similarity_fn (function): similarity function used to compute the overlap\n",
        "        samples (list of lists): tokenized version of the translated sentences\n",
        "        *ignore_params: additional parameters will be ignored\n",
        "\n",
        "    Returns:\n",
        "        dict: scores of each sample\n",
        "            key: index of the sample\n",
        "            value: score of the sample\n",
        "    \"\"\"  \n",
        "    \n",
        "    # initialize dictionary\n",
        "    scores = {}\n",
        "    \n",
        "    # run a for loop for each sample\n",
        "    for index_candidate, candidate in enumerate(samples):    \n",
        "        \n",
        "        # initialize overlap to 0.0\n",
        "        overlap = 0.0\n",
        "        \n",
        "        # run a for loop for each sample\n",
        "        for index_sample, sample in enumerate(samples): \n",
        "\n",
        "            # skip if the candidate index is the same as the sample index\n",
        "            if index_candidate == index_sample:\n",
        "                continue\n",
        "                \n",
        "            # get the overlap between candidate and sample using the similarity function\n",
        "            sample_overlap = similarity_fn(candidate,sample)\n",
        "            \n",
        "            # add the sample overlap to the total overlap\n",
        "            overlap += sample_overlap\n",
        "            \n",
        "        # get the score for the candidate by computing the average\n",
        "        score = overlap/index_sample\n",
        "        \n",
        "        # save the score in the dictionary. use index as the key.\n",
        "        scores[index_candidate] = score\n",
        "        \n",
        "    return scores"
      ],
      "metadata": {
        "id": "L0hP96QYb7Nw"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_overlap(jaccard_similarity, [[1, 2, 3], [1, 2, 4], [1, 2, 4, 5]], [0.4, 0.2, 0.5])"
      ],
      "metadata": {
        "id": "m3OHFqx6cGIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "622afe9d-3cd5-4f73-d2f3-de7f6f89e596"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.45, 1: 0.625, 2: 0.575}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_avg_overlap(similarity_fn, samples, log_probs):\n",
        "    \"\"\"Returns the weighted mean of each candidate sentence in the samples\n",
        "\n",
        "    Args:\n",
        "        samples (list of lists): tokenized version of the translated sentences\n",
        "        log_probs (list of float): log probability of the translated sentences\n",
        "\n",
        "    Returns:\n",
        "        dict: scores of each sample\n",
        "            key: index of the sample\n",
        "            value: score of the sample\n",
        "    \"\"\"\n",
        "    \n",
        "    # initialize dictionary\n",
        "    scores = {}\n",
        "    \n",
        "    # run a for loop for each sample\n",
        "    for index_candidate, candidate in enumerate(samples):    \n",
        "        \n",
        "        # initialize overlap and weighted sum\n",
        "        overlap, weight_sum = 0.0, 0.0\n",
        "        \n",
        "        # run a for loop for each sample\n",
        "        for index_sample, (sample, logp) in enumerate(zip(samples, log_probs)):\n",
        "\n",
        "            # skip if the candidate index is the same as the sample index            \n",
        "            if index_candidate == index_sample:\n",
        "                continue\n",
        "                \n",
        "            # convert log probability to linear scale\n",
        "            sample_p = float(np.exp(logp))\n",
        "\n",
        "            # update the weighted sum\n",
        "            weight_sum += sample_p\n",
        "\n",
        "            # get the unigram overlap between candidate and sample\n",
        "            sample_overlap = similarity_fn(candidate, sample)\n",
        "            \n",
        "            # update the overlap\n",
        "            overlap += sample_p * sample_overlap\n",
        "            \n",
        "        # get the score for the candidate\n",
        "        score = overlap / weight_sum\n",
        "        \n",
        "        # save the score in the dictionary. use index as the key.\n",
        "        scores[index_candidate] = score\n",
        "    \n",
        "    return scores"
      ],
      "metadata": {
        "id": "R1mfP-7fcP43"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_avg_overlap(jaccard_similarity, [[1, 2, 3], [1, 2, 4], [1, 2, 4, 5]], [0.4, 0.2, 0.5])"
      ],
      "metadata": {
        "id": "XmHl1rzgcQ5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40f6685c-1dff-4df2-b8fc-fd4b217fbbf3"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.44255574831883415, 1: 0.631244796869735, 2: 0.5575581009406329}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mbr_decode(sentence, n_samples, score_fn, similarity_fn, NMTAttn=None, temperature=0.6, vocab_file=None, vocab_dir=None):\n",
        "    \"\"\"Returns the translated sentence using Minimum Bayes Risk decoding\n",
        "\n",
        "    Args:\n",
        "        sentence (str): sentence to translate.\n",
        "        n_samples (int): number of samples to generate\n",
        "        score_fn (function): function that generates the score for each sample\n",
        "        similarity_fn (function): function used to compute the overlap between a pair of samples\n",
        "        NMTAttn (tl.Serial): An LSTM sequence-to-sequence model with attention.\n",
        "        temperature (float): parameter for sampling ranging from 0.0 to 1.0.\n",
        "            0.0: same as argmax, always pick the most probable token\n",
        "            1.0: sampling from the distribution (can sometimes say random things)\n",
        "        vocab_file (str): filename of the vocabulary\n",
        "        vocab_dir (str): path to the vocabulary file\n",
        "\n",
        "    Returns:\n",
        "        str: the translated sentence\n",
        "    \"\"\"\n",
        "    # generate samples\n",
        "    samples, log_probs = generate_samples(sentence, n_samples, NMTAttn, temperature, vocab_file, vocab_dir)\n",
        "    \n",
        "    # use the scoring function to get a dictionary of scores\n",
        "    # pass in the relevant parameters as shown in the function definition of \n",
        "    # the mean methods you developed earlier\n",
        "    scores = weighted_avg_overlap(jaccard_similarity, samples, log_probs)\n",
        "    \n",
        "    # find the key with the highest score\n",
        "    max_index = max(scores, key=scores.get)\n",
        "    \n",
        "    # detokenize the token list associated with the max_index\n",
        "    translated_sentence = detokenize(samples[max_index], vocab_file, vocab_dir)\n",
        "    \n",
        "    return (translated_sentence, max_index, scores)"
      ],
      "metadata": {
        "id": "Q5ygWApVcbJx"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEMPERATURE = 0.4\n",
        "\n",
        "# put a custom string here\n",
        "your_sentence = 'She speaks English and German.'"
      ],
      "metadata": {
        "id": "X7n6U_0GdEU2"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mbr_decode(your_sentence, 4, weighted_avg_overlap, jaccard_similarity, model, TEMPERATURE, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR)[0]"
      ],
      "metadata": {
        "id": "h-EUNeqfdLY-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b35b5d97-c37a-48fe-ffad-84136d747b62"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'starken Neo ien weniger FehlenneuDer kteBesitzReco.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mbr_decode('Congratulations!', 4, average_overlap, rouge1_similarity, model, TEMPERATURE, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR)[0]"
      ],
      "metadata": {
        "id": "yTrHNvwudPiW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "baf46ed4-1135-44c6-abdc-7c6a0658f731"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'%) 10,  9 dem Die Studien nahm'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mbr_decode('You have completed the assignment!', 4, average_overlap, rouge1_similarity, model, TEMPERATURE, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR)[0]"
      ],
      "metadata": {
        "id": "vTklGs7VdT7h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2cc5b192-0568-4bab-855e-427ce3d0cb29"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lgestudieég'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UnVLO0uBnrSn",
        "gB9vacDmoFxS",
        "MEtfcDRhqtmi",
        "WIfhmanStmtX",
        "z49ZCjziOqQh",
        "84L6q5NxROnP",
        "9RAu4y8rR8XT",
        "a00hphgqShVG",
        "M5VBx1umZSpP"
      ],
      "authorship_tag": "ABX9TyPByJP3IS686hzmbLCu4uUe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "27e0fdd437d3430f845f7c9fccef0074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2b3552819b249bca58fc49869dd8f99",
              "IPY_MODEL_bf0fa92b83844d6ba325fa88da57801c",
              "IPY_MODEL_e95f2799e1b140d4808d1b08dcbb2594"
            ],
            "layout": "IPY_MODEL_d7c1c25ed30f401487291c626cc47f89"
          }
        },
        "b2b3552819b249bca58fc49869dd8f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7d52cd5e8764fb7a4319a2b20b32a5d",
            "placeholder": "​",
            "style": "IPY_MODEL_cb5c3ee898f544d884ac7e09176cb9bf",
            "value": "Dl Completed...: 100%"
          }
        },
        "bf0fa92b83844d6ba325fa88da57801c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_110f11be7d354be58715f110ea22fa81",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc76b52a759449eb9e1ec574463c174e",
            "value": 1
          }
        },
        "e95f2799e1b140d4808d1b08dcbb2594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5f0edf88d72480085279e88baf77e92",
            "placeholder": "​",
            "style": "IPY_MODEL_53a025f085cf487c8e65bbf1d677e030",
            "value": " 1/1 [00:13&lt;00:00, 11.21s/ url]"
          }
        },
        "d7c1c25ed30f401487291c626cc47f89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7d52cd5e8764fb7a4319a2b20b32a5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb5c3ee898f544d884ac7e09176cb9bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "110f11be7d354be58715f110ea22fa81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "bc76b52a759449eb9e1ec574463c174e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5f0edf88d72480085279e88baf77e92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53a025f085cf487c8e65bbf1d677e030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e3421fecdff4821b7aab758193d7dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e16cb88c7264c6289c1f642760c9670",
              "IPY_MODEL_de0866419ff24a9b9fc417910bb8fa1d",
              "IPY_MODEL_6cc8fbdd73c74c1e95e33c26e0a90553"
            ],
            "layout": "IPY_MODEL_249002301b654123b2d8b19c3abdf2e2"
          }
        },
        "6e16cb88c7264c6289c1f642760c9670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e990eaf57171448c9f4264dc3c820a85",
            "placeholder": "​",
            "style": "IPY_MODEL_c1dbd727a2334976a8818908fae4cc4f",
            "value": "Dl Size...: 100%"
          }
        },
        "de0866419ff24a9b9fc417910bb8fa1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dfd26dd16eb45a58682cb8d4323751e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_142bafb2e84c46e2a3597bf03bbce27a",
            "value": 1
          }
        },
        "6cc8fbdd73c74c1e95e33c26e0a90553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ab20c49d4fa44bcbd5c7bd850c6ef2a",
            "placeholder": "​",
            "style": "IPY_MODEL_9d5f193b195a4e82bf0ad89991860226",
            "value": " 34/34 [00:13&lt;00:00,  6.88 MiB/s]"
          }
        },
        "249002301b654123b2d8b19c3abdf2e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e990eaf57171448c9f4264dc3c820a85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1dbd727a2334976a8818908fae4cc4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dfd26dd16eb45a58682cb8d4323751e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "142bafb2e84c46e2a3597bf03bbce27a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ab20c49d4fa44bcbd5c7bd850c6ef2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d5f193b195a4e82bf0ad89991860226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a3a41b94c324e00aecf501f55bbd6e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_331b05c1b5a446ecbe6f1d17c5e45dde",
              "IPY_MODEL_98e52c75cc1841ad9ae5986aa849d72a",
              "IPY_MODEL_0f27c9199347466182f7c1810710c0ec"
            ],
            "layout": "IPY_MODEL_0177e7532f42434d82858d58ecf40897"
          }
        },
        "331b05c1b5a446ecbe6f1d17c5e45dde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bf0906afc8b4e18ae0677db901978a8",
            "placeholder": "​",
            "style": "IPY_MODEL_d2a64d28f9ad4413b817ea0184fd6950",
            "value": "Extraction completed...: 100%"
          }
        },
        "98e52c75cc1841ad9ae5986aa849d72a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_331d7044e54f44e9ba3ae931357434a0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54192e55b9ec4e8d958ba26ca4207102",
            "value": 1
          }
        },
        "0f27c9199347466182f7c1810710c0ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7084d2a26c1a4272ae1d88a6db3e9d06",
            "placeholder": "​",
            "style": "IPY_MODEL_c94577c7bf284d97b8f5fe63c3674d86",
            "value": " 1/1 [00:13&lt;00:00, 13.66s/ file]"
          }
        },
        "0177e7532f42434d82858d58ecf40897": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bf0906afc8b4e18ae0677db901978a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2a64d28f9ad4413b817ea0184fd6950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "331d7044e54f44e9ba3ae931357434a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "54192e55b9ec4e8d958ba26ca4207102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7084d2a26c1a4272ae1d88a6db3e9d06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c94577c7bf284d97b8f5fe63c3674d86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "620489a85cda4fbcab0126ea4c77b163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8dae73bc2fc7409b902eb1be45668457",
              "IPY_MODEL_c15583fc61be454899432042e91469cb",
              "IPY_MODEL_b9b2dc432dee4e79a8cd6c814d29f0ee"
            ],
            "layout": "IPY_MODEL_5afb61c79031401bade793fedb737149"
          }
        },
        "8dae73bc2fc7409b902eb1be45668457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2b38bc1fd88470aa34b71a51bcf17f3",
            "placeholder": "​",
            "style": "IPY_MODEL_7df762cb64294493872ebf562593dc55",
            "value": "Generating splits...: 100%"
          }
        },
        "c15583fc61be454899432042e91469cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84d3b4c72f17441eac4b6a56d0712f91",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbc48e9dfbc649638ba01c25d0340e53",
            "value": 1
          }
        },
        "b9b2dc432dee4e79a8cd6c814d29f0ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03469cda67274859a6a14ea39c072f66",
            "placeholder": "​",
            "style": "IPY_MODEL_a41b98ce1faf4db1809ce7c6a8f43661",
            "value": " 1/1 [02:16&lt;00:00, 136.06s/ splits]"
          }
        },
        "5afb61c79031401bade793fedb737149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "e2b38bc1fd88470aa34b71a51bcf17f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7df762cb64294493872ebf562593dc55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84d3b4c72f17441eac4b6a56d0712f91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbc48e9dfbc649638ba01c25d0340e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03469cda67274859a6a14ea39c072f66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a41b98ce1faf4db1809ce7c6a8f43661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abcc08e028d34bb3af2d0d4a98a7336b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a912cc9392d4f99aaa626572408645f",
              "IPY_MODEL_285d6e29754d4b92911a217ee4a0c33c",
              "IPY_MODEL_069786d2e88c4fcb87a2e20ff9c7c8ae"
            ],
            "layout": "IPY_MODEL_ec6be27d9b81450ba17a04bb924d7c86"
          }
        },
        "4a912cc9392d4f99aaa626572408645f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69f08f1b00254e2ab51a9724392c1173",
            "placeholder": "​",
            "style": "IPY_MODEL_1bc80c204ecd482ab3be7ffb203d8395",
            "value": "Generating train examples...: 100%"
          }
        },
        "285d6e29754d4b92911a217ee4a0c33c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46e9c35740734e7f9100d0115b1bcdd8",
            "max": 1108752,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3699ebce8f954362af0e0c8d258f58b9",
            "value": 1108752
          }
        },
        "069786d2e88c4fcb87a2e20ff9c7c8ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a5051a6015b48679f6a087d66071418",
            "placeholder": "​",
            "style": "IPY_MODEL_d95cef6dd8af44beabb2db91a2ba3cfb",
            "value": " 1108303/1108752 [02:10&lt;00:00, 8944.81 examples/s]"
          }
        },
        "ec6be27d9b81450ba17a04bb924d7c86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "69f08f1b00254e2ab51a9724392c1173": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bc80c204ecd482ab3be7ffb203d8395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46e9c35740734e7f9100d0115b1bcdd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3699ebce8f954362af0e0c8d258f58b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a5051a6015b48679f6a087d66071418": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d95cef6dd8af44beabb2db91a2ba3cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4caff371d93e46c5916034e9f46e0ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5d2e20376b942fa96ce32578246dfa9",
              "IPY_MODEL_5c0bb740af7f49798d52d423323dabed",
              "IPY_MODEL_90b245cee7894b189652708f132c5aaf"
            ],
            "layout": "IPY_MODEL_4fc4ceeb86764293b265295081d76126"
          }
        },
        "d5d2e20376b942fa96ce32578246dfa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63da461635044eb790b51cc26ce98f1c",
            "placeholder": "​",
            "style": "IPY_MODEL_ec4d7f8b3c8f493aa5f5cb0d31db985f",
            "value": "Shuffling data/opus/medical/0.1.0.incomplete0QLOER/opus-train.tfrecord*...:  98%"
          }
        },
        "5c0bb740af7f49798d52d423323dabed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14c441b7d4b247da9eb0c60d5667cbd2",
            "max": 1108752,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16088c9346f84bdc9829d9d715b149f4",
            "value": 1108752
          }
        },
        "90b245cee7894b189652708f132c5aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c1df4203f664f358fae98f5b0f51b56",
            "placeholder": "​",
            "style": "IPY_MODEL_9b65199b366248df8b5b1eea539cc809",
            "value": " 1082958/1108752 [00:05&lt;00:00, 359612.79 examples/s]"
          }
        },
        "4fc4ceeb86764293b265295081d76126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "63da461635044eb790b51cc26ce98f1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec4d7f8b3c8f493aa5f5cb0d31db985f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14c441b7d4b247da9eb0c60d5667cbd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16088c9346f84bdc9829d9d715b149f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c1df4203f664f358fae98f5b0f51b56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b65199b366248df8b5b1eea539cc809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}